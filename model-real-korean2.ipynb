{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8943586,"sourceType":"datasetVersion","datasetId":5381596},{"sourceId":8944706,"sourceType":"datasetVersion","datasetId":5382426},{"sourceId":8949240,"sourceType":"datasetVersion","datasetId":5381653}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sikarosal/model-real-korean2?scriptVersionId=188451067\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/input/data-final/data_final.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-14T02:24:00.29765Z","iopub.execute_input":"2024-07-14T02:24:00.298204Z","iopub.status.idle":"2024-07-14T02:24:06.773627Z","shell.execute_reply.started":"2024-07-14T02:24:00.29817Z","shell.execute_reply":"2024-07-14T02:24:06.772849Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# !pip install -r /kaggle/input/requirements/requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-07-14T02:24:06.775236Z","iopub.execute_input":"2024-07-14T02:24:06.775542Z","iopub.status.idle":"2024-07-14T02:24:06.779487Z","shell.execute_reply.started":"2024-07-14T02:24:06.775517Z","shell.execute_reply":"2024-07-14T02:24:06.778478Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-07-14T02:24:06.780654Z","iopub.execute_input":"2024-07-14T02:24:06.781274Z","iopub.status.idle":"2024-07-14T02:24:07.015415Z","shell.execute_reply.started":"2024-07-14T02:24:06.781232Z","shell.execute_reply":"2024-07-14T02:24:07.014394Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 143223 entries, 0 to 143222\nData columns (total 16 columns):\n #   Column                  Non-Null Count   Dtype \n---  ------                  --------------   ----- \n 0   _id                     143223 non-null  object\n 1   mediaType               143223 non-null  object\n 2   gender                  143223 non-null  object\n 3   address                 143223 non-null  object\n 4   disasterLarge           143223 non-null  object\n 5   disasterMedium          143223 non-null  object\n 6   urgencyLevel            143223 non-null  object\n 7   sentiment               143223 non-null  object\n 8   symptom                 143223 non-null  object\n 9   triage                  93451 non-null   object\n 10  id                      143223 non-null  object\n 11  json_file_path          143223 non-null  object\n 12  wav_original_file_path  143223 non-null  object\n 13  text                    143223 non-null  object\n 14  endAt                   143223 non-null  int64 \n 15  label                   143223 non-null  bool  \ndtypes: bool(1), int64(1), object(14)\nmemory usage: 16.5+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport sys\n\n# 업로드한 파일들이 있는 디렉토리 경로 추가\nsys.path.append('/kaggle/input/codes-for-model')","metadata":{"execution":{"iopub.status.busy":"2024-07-14T02:24:07.016695Z","iopub.execute_input":"2024-07-14T02:24:07.017034Z","iopub.status.idle":"2024-07-14T02:24:07.02236Z","shell.execute_reply.started":"2024-07-14T02:24:07.017004Z","shell.execute_reply":"2024-07-14T02:24:07.021262Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-07-14T02:24:07.02585Z","iopub.execute_input":"2024-07-14T02:24:07.02619Z","iopub.status.idle":"2024-07-14T02:24:07.223407Z","shell.execute_reply.started":"2024-07-14T02:24:07.026159Z","shell.execute_reply":"2024-07-14T02:24:07.222264Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 143223 entries, 0 to 143222\nData columns (total 16 columns):\n #   Column                  Non-Null Count   Dtype \n---  ------                  --------------   ----- \n 0   _id                     143223 non-null  object\n 1   mediaType               143223 non-null  object\n 2   gender                  143223 non-null  object\n 3   address                 143223 non-null  object\n 4   disasterLarge           143223 non-null  object\n 5   disasterMedium          143223 non-null  object\n 6   urgencyLevel            143223 non-null  object\n 7   sentiment               143223 non-null  object\n 8   symptom                 143223 non-null  object\n 9   triage                  93451 non-null   object\n 10  id                      143223 non-null  object\n 11  json_file_path          143223 non-null  object\n 12  wav_original_file_path  143223 non-null  object\n 13  text                    143223 non-null  object\n 14  endAt                   143223 non-null  int64 \n 15  label                   143223 non-null  bool  \ndtypes: bool(1), int64(1), object(14)\nmemory usage: 16.5+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"df.drop('label',axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T02:24:07.225082Z","iopub.execute_input":"2024-07-14T02:24:07.22539Z","iopub.status.idle":"2024-07-14T02:24:07.272258Z","shell.execute_reply.started":"2024-07-14T02:24:07.225362Z","shell.execute_reply":"2024-07-14T02:24:07.271311Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df['label']=df['urgencyLevel']","metadata":{"execution":{"iopub.status.busy":"2024-07-14T02:24:07.273506Z","iopub.execute_input":"2024-07-14T02:24:07.273831Z","iopub.status.idle":"2024-07-14T02:24:07.282514Z","shell.execute_reply.started":"2024-07-14T02:24:07.273802Z","shell.execute_reply":"2024-07-14T02:24:07.281635Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ndf['label']=le.fit_transform(df['label'])\ndf['label']","metadata":{"execution":{"iopub.status.busy":"2024-07-14T02:24:07.284023Z","iopub.execute_input":"2024-07-14T02:24:07.284346Z","iopub.status.idle":"2024-07-14T02:24:07.824599Z","shell.execute_reply.started":"2024-07-14T02:24:07.284308Z","shell.execute_reply":"2024-07-14T02:24:07.823495Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"0         1\n1         1\n2         1\n3         2\n4         2\n         ..\n143218    0\n143219    0\n143220    0\n143221    0\n143222    0\nName: label, Length: 143223, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df.drop(columns=['_id','triage','mediaType','gender','address',\n                 'disasterLarge','disasterMedium','urgencyLevel','symptom','sentiment'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T02:24:07.825925Z","iopub.execute_input":"2024-07-14T02:24:07.8262Z","iopub.status.idle":"2024-07-14T02:24:07.858717Z","shell.execute_reply.started":"2024-07-14T02:24:07.826175Z","shell.execute_reply":"2024-07-14T02:24:07.857963Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-07-14T02:24:07.860101Z","iopub.execute_input":"2024-07-14T02:24:07.860373Z","iopub.status.idle":"2024-07-14T02:24:07.929926Z","shell.execute_reply.started":"2024-07-14T02:24:07.860349Z","shell.execute_reply":"2024-07-14T02:24:07.928884Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 143223 entries, 0 to 143222\nData columns (total 6 columns):\n #   Column                  Non-Null Count   Dtype \n---  ------                  --------------   ----- \n 0   id                      143223 non-null  object\n 1   json_file_path          143223 non-null  object\n 2   wav_original_file_path  143223 non-null  object\n 3   text                    143223 non-null  object\n 4   endAt                   143223 non-null  int64 \n 5   label                   143223 non-null  int64 \ndtypes: int64(2), object(4)\nmemory usage: 6.6+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"from model import *","metadata":{"execution":{"iopub.status.busy":"2024-07-14T02:24:07.931033Z","iopub.execute_input":"2024-07-14T02:24:07.9313Z","iopub.status.idle":"2024-07-14T02:24:12.623045Z","shell.execute_reply.started":"2024-07-14T02:24:07.931266Z","shell.execute_reply":"2024-07-14T02:24:12.62229Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from collections import OrderedDict\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import AutoModel\n\nclass Baseline(nn.Module):\n    def __init__(self,\n                 model_link='beomi/KcELECTRA-base-v2022',\n                 class_num=3):\n        super(Baseline, self).__init__()\n        self.electra = AutoModel.from_pretrained(model_link)\n        \n        self.classifier = nn.Sequential(OrderedDict([\n            ('dense',nn.Linear(768, 768)),\n            ('dropout', nn.Dropout(0.1)),\n            ('out_proj', nn.Linear(768, class_num)),\n        ]))\n        \n    def encode(self, input_ids, att_mask, token_type_ids):\n        output = self.electra(input_ids, att_mask, token_type_ids)\n        last_hidden_state = output.last_hidden_state\n        \n        # cls = torch.mean(last_hidden_state, dim=1)\n        cls = last_hidden_state[:, 0, :]\n        return cls\n        \n    def forward(self, input_ids, att_mask, token_type_ids):\n        output = self.electra(input_ids, att_mask, token_type_ids)\n        last_hidden_state = output.last_hidden_state\n        \n        # cls = torch.mean(last_hidden_state, dim=1)\n        cls = last_hidden_state[:, 0, :]\n        logit = self.classifier(cls)\n        return logit\n\ndef get_Model(class_name):\n    try:\n        Myclass = eval(class_name)()\n        return Myclass\n    except NameError as e:\n        print(\"Class [{}] is not defined\".format(class_name))\n\ndef main():\n    pass\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2024-07-14T02:24:12.624007Z","iopub.execute_input":"2024-07-14T02:24:12.624386Z","iopub.status.idle":"2024-07-14T02:24:12.634862Z","shell.execute_reply.started":"2024-07-14T02:24:12.624363Z","shell.execute_reply":"2024-07-14T02:24:12.633934Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# https://github.com/HideOnHouse/TorchBase\n\nimport os\nimport glob\nimport wandb\nimport pickle\nimport argparse\nimport pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split, RandomSampler\n\nfrom transformers import AutoTokenizer\nfrom transformers import get_cosine_schedule_with_warmup\nfrom transformers import get_linear_schedule_with_warmup\n\nfrom dataset import *\nfrom learning import *\n\nfrom data_processing import *\n# from inference import *\n# from inference_switching_recall import *\nfrom utils import DataParallelModel, DataParallelCriterion\nfrom utils import set_device, set_save_path, set_label_frequency, str2bool, calc_metric\n\nimport warnings\nwarnings.filterwarnings(action='ignore')\n\nSEED = 42 # 17\n# random.seed(SEED) #  Python의 random 라이브러리가 제공하는 랜덤 연산이 항상 동일한 결과를 출력하게끔\nos.environ['PYTHONHASHSEED'] = str(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\n\ndef main():\n    is_scratch = True\n    \n    # Define project\n    WANDB_AUTH_KEY = '8f36d8b64d0df471fb52315584870902fa63618f'\n    project_name = 'new_project'\n    model_name = 'Only_Text_{}'.format('scratch' if is_scratch else 'ckpt')\n    model_link = 'beomi/KcELECTRA-base-v2022' #'beomi/kcbert-base'\n\n    wandb.login(key=WANDB_AUTH_KEY)\n    wandb.init(project=project_name)\n    wandb.run.name = model_name\n\n    # args\n    epochs = 7\n    batch_size = 48 # 128 + 64 + 32\n    electra_lr = 2e-5\n    cls_lr = 2e-3\n    \n    class_num = 3\n    max_length = 384 # 384\n    padding = 'max_length'\n    upsampling_rate = 0.0\n    by_file = True\n    save_term = 100\n    \n    def set_device(main_device_num=0, using_device_num=1):\n        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        device_ids = list(range(main_device_num, main_device_num + using_device_num))\n        if device == 'cuda':\n            device += ':{}'.format(main_device_num)\n        print(device,device_ids)\n        return device, device_ids\n    \n    main_device, device_ids = set_device(main_device_num=0, using_device_num=2)\n    save_path = set_save_path(model_name, epochs, batch_size)\n\n    # Datasets\n    # train_path, valid_path, test_path = data_processing(root_path=os.path.join('파일 path 입력'), \n    #                                                     save_path=os.path.join('파일 저장 경로 입력'))\n    # data_propressing 함수에 문제가 발생할 경우, 해당 line 주석처리 후 아래 주석의 코드를 실행\n    \n    y = df['label']  # 레이블 컬럼을 y로 지정\n\n    x_train, x_valid = train_test_split(df, test_size=0.2, random_state=32, stratify=y)\n\n    train_data = x_train\n    valid_data = x_valid\n    valid_file_ids = valid_data.id\n\n    valid_file_ids = valid_data.id\n\n    ## your Data Pre-Processing\n    print('init Data >>>')\n    print('\\ttrain data :', train_data.shape)\n    print('\\tvalid data :', valid_data.shape)\n\n    train_data = train_data.dropna(axis=0)\n    train_data = train_data.reset_index(drop=True)\n    valid_data = valid_data.dropna(axis=0)\n    valid_data = valid_data.reset_index(drop=True)\n\n    print('Drop nan >>>')\n    print('\\ttrain data :', train_data.shape)\n    print('\\tvalid data :', valid_data.shape)\n    \n    # print('Only One Sequence >>>')\n    # train_data = set_last_sequence(train_data, end_time=120000, cut=False)\n    # valid_data = set_last_sequence(valid_data, end_time=120000, cut=False)\n    # test_data = set_last_sequence(test_data, end_time=120000, cut=True)\n    # print('\\ttrain data :', train_data.shape)\n    # print('\\tvalid data :', valid_data.shape)\n    # print('\\ttest data :', test_data.shape)\n\n    print(f'Up-Sampling Label 0 >>> rate : {upsampling_rate}')\n    train_data, train_label_frequency = set_label_frequency(train_data, rate=upsampling_rate, target_label=1, by_file=by_file)\n    valid_data, valid_label_frequency = set_label_frequency(valid_data, rate=0.0, target_label=1, by_file=by_file)\n  \n    print('\\ttrain data :', train_data.shape)\n    print('\\tvalid data :', valid_data.shape)\n    \n    ## Create Dataset and DataLoader\n    tokenizer = AutoTokenizer.from_pretrained(model_link)\n    train_dataset = MyDataset(train_data, \n                              tokenizer, \n                              max_length=max_length, \n                              padding=padding,\n                              class_num=class_num)\n    valid_dataset = MyDataset(valid_data,\n                              tokenizer,\n                              max_length=max_length,\n                              padding=padding,\n                              class_num=class_num)\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=RandomSampler(train_dataset), num_workers=4)\n    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=4)\n\n    ## label_frequency\n    train_label_frequency = (train_data.label == 1).sum() / len(train_data)\n    valid_label_frequency = (valid_data.label == 1).sum() / len(valid_data)\n    print(\"Label frequency of Train Data: {:6f}\".format(train_label_frequency))\n    print(\"Label frequency of Valid Data: {:6f}\".format(valid_label_frequency))\n    \n    # modeling\n    if is_scratch:\n        model = Baseline(model_link=model_link, class_num=3)\n        print(device_ids)\n        model = DataParallelModel(model, device_ids=device_ids)#; model.to(device)\n    else:\n        check_path = os.path.join('models', 'One_Sequence_2m_O_72%_max_seq_256_e20_bs192', 'checkpoint_2_200.tar')\n        model = Baseline(model_link=model_link, class_num=3)\n        ckpt = torch.load(check_path, map_location=main_device)\n        model.load_state_dict(ckpt['model_state_dict']); model.to(main_device)\n        model = DataParallelModel(model, device_ids=device_ids)\n\n    optimizer = optim.AdamW([{'params': model.module.electra.parameters(),'lr': electra_lr},\n                             {'params': model.module.classifier.parameters(),'lr': cls_lr}],\n                            eps=1e-8)\n    criterion = torch.nn.CrossEntropyLoss()\n    criterion = DataParallelCriterion(criterion, device_ids=device_ids)\n    \n    iter_len = len(train_loader)\n    num_training_steps = iter_len * epochs\n    num_warmup_steps = int(0.15 * num_training_steps)\n    scheduler = get_linear_schedule_with_warmup(optimizer,\n                                                num_warmup_steps=num_warmup_steps,\n                                                num_training_steps=num_training_steps)\n\n    config = {\n        'electra_lr': electra_lr,\n        'cls_lr': cls_lr,\n        'batch_size': batch_size,\n        'epochs': epochs,\n        'max_length': max_length,\n        'train_label_frequency': train_label_frequency,\n        'valid_label_frequency': valid_label_frequency,\n        'upsampling_rate': upsampling_rate,\n        'by_file':by_file\n    }\n    wandb.config.update(config)\n\n    # Train\n    print(\"============================= Train =============================\")\n    model = train(train_label_frequency, scheduler, model, main_device, optimizer, criterion, epochs, save_path, train_loader, valid_loader, save_term)\n\nif __name__ == '__main__':\n    main()\n    # CUDA_VISIBLE_DEVICES=0,1,2,3 python main.py\n    # CUDA_VISIBLE_DEVICES=1,2,3,4 python main.py\n    # CUDA_VISIBLE_DEVICES= python main.py","metadata":{"execution":{"iopub.status.busy":"2024-07-14T02:24:12.636115Z","iopub.execute_input":"2024-07-14T02:24:12.636519Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbellkjtt\u001b[0m (\u001b[33msikaro\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240714_022415-wp0dcs0p</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sikaro/new_project/runs/wp0dcs0p' target=\"_blank\">eager-voice-2</a></strong> to <a href='https://wandb.ai/sikaro/new_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sikaro/new_project' target=\"_blank\">https://wandb.ai/sikaro/new_project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sikaro/new_project/runs/wp0dcs0p' target=\"_blank\">https://wandb.ai/sikaro/new_project/runs/wp0dcs0p</a>"},"metadata":{}},{"name":"stdout","text":"cuda:0 [0, 1]\ninit Data >>>\n\ttrain data : (114578, 6)\n\tvalid data : (28645, 6)\nDrop nan >>>\n\ttrain data : (114578, 6)\n\tvalid data : (28645, 6)\nUp-Sampling Label 0 >>> rate : 0.0\n\ttrain data : (114578, 6)\n\tvalid data : (28645, 6)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/288 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91a530ff27f046239fdb74d3929fd4b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/504 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd400db42d784ffaa59bfa669d4a7300"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/450k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4952f10883664b0a9361615c84913ebd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0635f025ee214e9597c2cdc01f2b591c"}},"metadata":{}},{"name":"stdout","text":"Label frequency of Train Data: 0.335134\nLabel frequency of Valid Data: 0.339012\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/511M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d073766ca31404d92be22994ff29581"}},"metadata":{}},{"name":"stdout","text":"[0, 1]\n============================= Train =============================\n100%|██████████| 2388/2388 [1:06:03<00:00,  1.66s/it, epoch=1/7, loss=0.9475, acc=0.5191]\n100%|██████████| 597/597 [05:59<00:00,  1.66it/s, loss=0.9220, acc=0.5226]\nval loss : 0.921991\nval acc : 0.523\nval acc(th) : 0.522604\nval AUROC : 0.7700\nval AUPRC : 0.6269\nval Recall : 0.522271\nval Precision : 0.5461\nval F1_score : 0.4262\nval Brier : 0.186159\n\n100%|██████████| 2388/2388 [1:06:04<00:00,  1.66s/it, epoch=2/7, loss=0.8688, acc=0.5762]\n100%|██████████| 597/597 [06:00<00:00,  1.66it/s, loss=0.8820, acc=0.5832]\nval loss : 0.882026\nval acc : 0.583\nval acc(th) : 0.583173\nval AUROC : 0.7834\nval AUPRC : 0.6477\nval Recall : 0.589033\nval Precision : 0.5811\nval F1_score : 0.5791\nval Brier : 0.175349\n\n 71%|███████   | 1701/2388 [47:05<19:03,  1.66s/it, epoch=3/7, loss=0.8227, acc=0.6061] ","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['label'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}