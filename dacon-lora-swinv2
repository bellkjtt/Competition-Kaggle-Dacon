{"metadata":{"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8262444,"sourceType":"datasetVersion","datasetId":4904249}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### 라이브러리 설치","metadata":{}},{"cell_type":"code","source":"!pip install torch evaluate accelerate==0.27.2 dataset transformers scikit-learn pandas tqdm","metadata":{"execution":{"iopub.status.busy":"2024-04-30T01:39:17.536460Z","iopub.execute_input":"2024-04-30T01:39:17.536914Z","iopub.status.idle":"2024-04-30T01:39:20.781396Z","shell.execute_reply.started":"2024-04-30T01:39:17.536877Z","shell.execute_reply":"2024-04-30T01:39:20.779383Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2+cpu)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.1)\nRequirement already satisfied: accelerate==0.27.2 in /opt/conda/lib/python3.10/site-packages (0.27.2)\nRequirement already satisfied: dataset in /opt/conda/lib/python3.10/site-packages (1.6.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (6.0.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (0.22.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (0.4.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: sqlalchemy<2.0.0,>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from dataset) (1.4.52)\nRequirement already satisfied: alembic>=0.6.2 in /opt/conda/lib/python3.10/site-packages (from dataset) (1.13.1)\nRequirement already satisfied: banal>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from dataset) (1.0.6)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"### 클래스 별로 이미지 정리","metadata":{}},{"cell_type":"code","source":"!pip install -q -U transformers==4.38.2\n!pip install -q -U datasets==2.18.0\n!pip install -q -U bitsandbytes==0.42.0\n!pip install -q -U peft==0.9.0\n!pip install -q -U trl==0.7.11\n!pip install -q -U accelerate==0.27.2","metadata":{"execution":{"iopub.status.busy":"2024-04-30T01:39:20.784545Z","iopub.execute_input":"2024-04-30T01:39:20.785250Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# access token을 복사하세요.\nHF_TOKEN = \"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\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport shutil\nimport peft\nfrom tqdm.auto import notebook_tqdm\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./prepare-data')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/prepare-data/train.csv')\ntrain_df, valid_df = train_test_split(df, test_size=0.1, random_state=42,shuffle=True)\ntrain_df.reset_index(inplace=True, drop=True)\nvalid_df.reset_index(inplace=True, drop=True)\n\ntrain_df.to_csv(\"./prepare-data/train_df.csv\", index=False)\nvalid_df.to_csv(\"./prepare-data/valid_df.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['label'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = \"./prepare_data/train/\"\nvalid_dir = \"./prepare_data/valid/\"\n\ndef make_data(df, output_dir):\n    for index, row in notebook_tqdm(df.iterrows()):\n        src_path = os.path.join('/kaggle/input/prepare-data', row['img_path'].lstrip('./'))\n        label = row['label']\n        dest_dir = os.path.join(output_dir, label)\n    \n        if not os.path.exists(dest_dir):\n            os.makedirs(dest_dir)\n    \n        file_name = os.path.basename(src_path)\n        dest_path = os.path.join(dest_dir, file_name)\n\n        # 파일 존재 여부 확인\n        if os.path.exists(src_path):\n            shutil.copy(src_path, dest_path)\n        else:\n            print(f\"파일이 존재하지 않습니다: {src_path}\")\n            \n    print(\"파일 이동이 완료되었습니다.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_data(train_df, train_dir)\nmake_data(valid_df, valid_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Huggingface Library를 이용한 이미지 분류","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport random\nimport torch\nimport numpy as np\nimport os\nfrom datasets import load_dataset\nfrom evaluate import load\nfrom transformers import AutoModelForImageClassification, AutoImageProcessor, TrainingArguments, Trainer\nfrom trl import SFTTrainer\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(42)  \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset(\"imagefolder\", data_dir=\"./prepare_data/\")\ndataset = dataset.rename_column(\"label\", \"labels\")\n\nmodel_name = \"microsoft/swinv2-large-patch4-window12to16-192to256-22kto1k-ft\"\nprocessor = AutoImageProcessor.from_pretrained(model_name,)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform(example_batch):\n    inputs = processor([x for x in example_batch['image']], return_tensors='pt')\n    inputs['labels'] = example_batch['labels']\n    return inputs\n\ndef collate_fn(batch):\n    return {\n        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n        'labels': torch.tensor([x['labels'] for x in batch])\n    }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prepared_ds = dataset.with_transform(transform).shuffle()\n\nmetric = load(\"f1\", trust_remote_code=True)\ndef compute_metrics(p):\n    return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport torch\nfrom datasets import Dataset\nfrom transformers import (AutoTokenizer,\n                          AutoModelForCausalLM,\n                          BitsAndBytesConfig,\n                          pipeline,\n                          TrainingArguments)\nfrom peft import (LoraConfig,\n                  PeftModel)\nfrom trl import SFTTrainer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4 bits quantize 설정 선언\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",  # NormalFloat 4\n    bnb_4bit_compute_dtype=torch.float16\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lora_config = peft.LoraConfig(\n    r=16,\n    lora_alpha=16,\n    target_modules=['query','key','value'],\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=\"SEQUENCE_CLASSIFICATION\",\n    modules_to_save=[\"classifier\"]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = dataset['train'].features['labels'].names\n\nmodel = AutoModelForImageClassification.from_pretrained(\n    model_name,\n#     quantization_config=quantization_config,\n    num_labels=len(labels),\n    id2label={str(i): c for i, c in enumerate(labels)},\n    label2id={c: str(i) for i, c in enumerate(labels)},\n    ignore_mismatched_sizes=True,\n    token=HF_TOKEN,\n)\n\nprint_trainable_parameters(model)\nlora_model = get_peft_model(model, lora_config)\nprint_trainable_parameters(lora_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results/swinvit-experience-1\",\n    per_device_train_batch_size=16,\n    gradient_accumulation_steps=4,\n    per_device_eval_batch_size=16,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_strategy=\"epoch\",\n    save_total_limit=2,\n    num_train_epochs=200,\n    learning_rate=5e-5,\n#     fp16=True,\n    remove_unused_columns=False,\n    label_smoothing_factor=0.1,\n    warmup_ratio=0.1,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1\",\n    seed=42\n    \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=collate_fn,\n    compute_metrics=compute_metrics,\n    train_dataset=prepared_ds[\"train\"],\n    eval_dataset=prepared_ds[\"validation\"],\n    tokenizer=processor,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_results = trainer.train()\ntrainer.save_model()\ntrainer.log_metrics(\"train\", train_results.metrics)\ntrainer.save_metrics(\"train\", train_results.metrics)\ntrainer.save_state()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = trainer.evaluate(prepared_ds['validation'])\ntrainer.log_metrics(\"eval\", metrics)\ntrainer.save_metrics(\"eval\", metrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 추론","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nfrom transformers import AutoImageProcessor, AutoModelForImageClassification, pipeline\nfrom tqdm.auto import notebook_tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"microsoft/swinv2-large-patch4-window12to16-192to256-22kto1k-ft\"\nprocessor = AutoImageProcessor.from_pretrained(model_name, return_tensor=\"pt\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForImageClassification.from_pretrained(\"./best/checkpoint-2341/\")\nmodel.eval()\n\nclassifier = pipeline(\"image-classification\", model=model, image_processor=processor)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"./data/test.csv\")\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_file_name = test_df['img_path'].to_list()\n\npredict_labels = []\n\nfor idx, name in notebook_tqdm(enumerate(test_file_name), total=len(test_file_name)):\n    image = Image.open(os.path.join(\"./data/\", name.strip('./')))\n    predict_labels.append(classifier(image)[0]['label'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.read_csv(\"./data/sample_submission.csv\")\nsubmission_df.head()\nsubmission_df['label'] = predict_labels\nsubmission_df.to_csv(\"./submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}