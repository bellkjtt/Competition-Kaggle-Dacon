{"metadata":{"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8262444,"sourceType":"datasetVersion","datasetId":4904249}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### 라이브러리 설치","metadata":{}},{"cell_type":"code","source":"!pip install torch evaluate accelerate==0.27.2 dataset transformers scikit-learn pandas tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 클래스 별로 이미지 정리","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport shutil\nfrom tqdm.auto import notebook_tqdm\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-05-01T09:21:12.634451Z","iopub.execute_input":"2024-05-01T09:21:12.634843Z","iopub.status.idle":"2024-05-01T09:21:13.522953Z","shell.execute_reply.started":"2024-05-01T09:21:12.634810Z","shell.execute_reply":"2024-05-01T09:21:13.521972Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/prepare-data/train.csv')\ntrain_df, valid_df = train_test_split(df, test_size=0.1, random_state=42,shuffle=True)\ntrain_df.reset_index(inplace=True, drop=True)\nvalid_df.reset_index(inplace=True, drop=True)\n\ntrain_df.to_csv(\"./prepare-data/train_df.csv\", index=False)\nvalid_df.to_csv(\"./prepare-data/valid_df.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T09:21:13.524737Z","iopub.execute_input":"2024-05-01T09:21:13.525707Z","iopub.status.idle":"2024-05-01T09:21:13.634495Z","shell.execute_reply.started":"2024-05-01T09:21:13.525671Z","shell.execute_reply":"2024-05-01T09:21:13.633350Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_dir = \"./prepare_data/train/\"\nvalid_dir = \"./prepare_data/valid/\"\n\ndef make_data(df, output_dir):\n    for index, row in notebook_tqdm(df.iterrows()):\n        src_path = os.path.join('/kaggle/input/prepare-data', row['img_path'].lstrip('./'))\n        label = row['label']\n        dest_dir = os.path.join(output_dir, label)\n    \n        if not os.path.exists(dest_dir):\n            os.makedirs(dest_dir)\n    \n        file_name = os.path.basename(src_path)\n        dest_path = os.path.join(dest_dir, file_name)\n\n        # 파일 존재 여부 확인\n        if os.path.exists(src_path):\n            shutil.copy(src_path, dest_path)\n        else:\n            print(f\"파일이 존재하지 않습니다: {src_path}\")\n            \n    print(\"파일 이동이 완료되었습니다.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-01T09:21:13.652360Z","iopub.execute_input":"2024-05-01T09:21:13.652684Z","iopub.status.idle":"2024-05-01T09:21:13.660360Z","shell.execute_reply.started":"2024-05-01T09:21:13.652656Z","shell.execute_reply":"2024-05-01T09:21:13.659315Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# make_data(train_df, train_dir)\n# make_data(valid_df, valid_dir)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T09:21:13.981073Z","iopub.execute_input":"2024-05-01T09:21:13.981966Z","iopub.status.idle":"2024-05-01T09:21:13.986029Z","shell.execute_reply.started":"2024-05-01T09:21:13.981929Z","shell.execute_reply":"2024-05-01T09:21:13.985034Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Huggingface Library를 이용한 이미지 분류","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport random\nimport torch\nimport numpy as np\nimport os\nfrom datasets import load_dataset\nfrom evaluate import load\nfrom transformers import AutoModelForImageClassification, AutoImageProcessor, TrainingArguments, Trainer\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(42)  \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-05-01T09:21:14.522241Z","iopub.execute_input":"2024-05-01T09:21:14.522587Z","iopub.status.idle":"2024-05-01T09:21:21.138611Z","shell.execute_reply.started":"2024-05-01T09:21:14.522562Z","shell.execute_reply":"2024-05-01T09:21:21.137800Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-05-01 09:21:18.110070: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-01 09:21:18.110127: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-01 09:21:18.111596: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2024-05-01T09:21:21.140627Z","iopub.execute_input":"2024-05-01T09:21:21.141361Z","iopub.status.idle":"2024-05-01T09:21:21.148571Z","shell.execute_reply.started":"2024-05-01T09:21:21.141325Z","shell.execute_reply":"2024-05-01T09:21:21.147698Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"dataset = load_dataset(\"imagefolder\", data_dir=\"./prepare_data/\")\ndataset = dataset.rename_column(\"label\", \"labels\")\n\nmodel_name = \"microsoft/swinv2-large-patch4-window12to24-192to384-22kto1k-ft\"\nprocessor = AutoImageProcessor.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T09:21:21.149668Z","iopub.execute_input":"2024-05-01T09:21:21.150041Z","iopub.status.idle":"2024-05-01T09:22:07.185614Z","shell.execute_reply.started":"2024-05-01T09:21:21.150009Z","shell.execute_reply":"2024-05-01T09:22:07.184886Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/14250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96c4aca522b5492b969fea7e81dbd38e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/1584 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10e422373caf44159b3d8108b95ba69d"}},"metadata":{}},{"name":"stderr","text":"Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n","output_type":"stream"}]},{"cell_type":"code","source":"def transform(example_batch):\n    inputs = processor([x for x in example_batch['image']], return_tensors='pt')\n    inputs['labels'] = example_batch['labels']\n    return inputs\n\ndef collate_fn(batch):\n    return {\n        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n        'labels': torch.tensor([x['labels'] for x in batch])\n    }","metadata":{"execution":{"iopub.status.busy":"2024-05-01T09:22:07.188603Z","iopub.execute_input":"2024-05-01T09:22:07.189015Z","iopub.status.idle":"2024-05-01T09:22:07.195085Z","shell.execute_reply.started":"2024-05-01T09:22:07.188979Z","shell.execute_reply":"2024-05-01T09:22:07.194230Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"prepared_ds = dataset.with_transform(transform).shuffle()\n\nmetric = load(\"f1\", trust_remote_code=True)\ndef compute_metrics(p):\n    return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids,average=\"macro\")","metadata":{"execution":{"iopub.status.busy":"2024-05-01T09:22:07.196253Z","iopub.execute_input":"2024-05-01T09:22:07.196568Z","iopub.status.idle":"2024-05-01T09:22:08.219581Z","shell.execute_reply.started":"2024-05-01T09:22:07.196534Z","shell.execute_reply":"2024-05-01T09:22:08.218799Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n    )","metadata":{"execution":{"iopub.status.busy":"2024-05-01T09:22:08.220883Z","iopub.execute_input":"2024-05-01T09:22:08.221244Z","iopub.status.idle":"2024-05-01T09:22:08.227956Z","shell.execute_reply.started":"2024-05-01T09:22:08.221208Z","shell.execute_reply":"2024-05-01T09:22:08.226921Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"labels = dataset['train'].features['labels'].names\n\nmodel = AutoModelForImageClassification.from_pretrained(\n    model_name,\n    num_labels=len(labels),\n    id2label={str(i): c for i, c in enumerate(labels)},\n    label2id={c: str(i) for i, c in enumerate(labels)},\n    ignore_mismatched_sizes=True\n)\n\nprint_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T09:22:08.229269Z","iopub.execute_input":"2024-05-01T09:22:08.229625Z","iopub.status.idle":"2024-05-01T09:22:10.936582Z","shell.execute_reply.started":"2024-05-01T09:22:08.229577Z","shell.execute_reply":"2024-05-01T09:22:10.935715Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Some weights of Swinv2ForImageClassification were not initialized from the model checkpoint at microsoft/swinv2-large-patch4-window12to24-192to384-22kto1k-ft and are newly initialized because the shapes did not match:\n- classifier.weight: found shape torch.Size([1000, 1536]) in the checkpoint and torch.Size([25, 1536]) in the model instantiated\n- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([25]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 195241357 || all params: 195241357 || trainable%: 100.00\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results/swinvit-experience-1\",\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=8,\n    per_device_eval_batch_size=4,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_steps=5,\n    save_total_limit=2,\n    num_train_epochs=20,\n    learning_rate=5e-5,\n    remove_unused_columns=False,\n    label_smoothing_factor=0.1,\n    warmup_ratio=0.1,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1\",\n    seed=42\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T09:22:10.937711Z","iopub.execute_input":"2024-05-01T09:22:10.938037Z","iopub.status.idle":"2024-05-01T09:22:10.947965Z","shell.execute_reply.started":"2024-05-01T09:22:10.938012Z","shell.execute_reply":"2024-05-01T09:22:10.947059Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T09:22:10.949169Z","iopub.execute_input":"2024-05-01T09:22:10.949476Z","iopub.status.idle":"2024-05-01T09:22:10.955511Z","shell.execute_reply.started":"2024-05-01T09:22:10.949452Z","shell.execute_reply":"2024-05-01T09:22:10.954608Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model.to(device),\n    args=training_args,\n    data_collator=collate_fn,\n    compute_metrics=compute_metrics,\n    train_dataset=prepared_ds[\"train\"],\n    eval_dataset=prepared_ds[\"validation\"],\n    tokenizer=processor,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T09:22:10.958511Z","iopub.execute_input":"2024-05-01T09:22:10.958832Z","iopub.status.idle":"2024-05-01T09:22:11.628847Z","shell.execute_reply.started":"2024-05-01T09:22:10.958809Z","shell.execute_reply":"2024-05-01T09:22:11.628015Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_results = trainer.train()\ntrainer.save_model()\ntrainer.log_metrics(\"train\", train_results.metrics)\ntrainer.save_metrics(\"train\", train_results.metrics)\ntrainer.save_state()","metadata":{"execution":{"iopub.status.busy":"2024-05-01T09:22:11.630130Z","iopub.execute_input":"2024-05-01T09:22:11.630503Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbellkjtt\u001b[0m (\u001b[33msikaro\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240501_092213-racvj5ii</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sikaro/huggingface/runs/racvj5ii' target=\"_blank\">pretty-dawn-13</a></strong> to <a href='https://wandb.ai/sikaro/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sikaro/huggingface' target=\"_blank\">https://wandb.ai/sikaro/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sikaro/huggingface/runs/racvj5ii' target=\"_blank\">https://wandb.ai/sikaro/huggingface/runs/racvj5ii</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='52' max='4450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  52/4450 05:55 < 8:41:08, 0.14 it/s, Epoch 0.11/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"torch.cuda.empty_cache()\nmodel.to('cpu')\ndel model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = trainer.evaluate(prepared_ds['validation'])\ntrainer.log_metrics(\"eval\", metrics)\ntrainer.save_metrics(\"eval\", metrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 추론","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nfrom transformers import AutoImageProcessor, AutoModelForImageClassification, pipeline\nfrom tqdm.auto import notebook_tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"microsoft/swinv2-large-patch4-window12to16-192to256-22kto1k-ft\"\nprocessor = AutoImageProcessor.from_pretrained(model_name, return_tensor=\"pt\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = dataset['train'].features['labels'].names\nk= glob.glob('/kaggle/working/ft-vit-base-patch16-224-in21k-on-food101-lora')[0]\nmodel = AutoModelForImageClassification.from_pretrained(k,\n                                                       num_labels=len(labels),\n    id2label={int(i): c for i, c in enumerate(labels)},\n    label2id={c: int(i) for i, c in enumerate(labels)},\n    ignore_mismatched_sizes=True,\n                                                       \n                                                       )\nmodel.eval()\n\nclassifier = pipeline(\"image-classification\", model=model, image_processor=processor)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/prepare-data/test.csv\")\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_file_name = test_df['img_path'].to_list()\npredict_labels = []\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nfor idx, name in notebook_tqdm(enumerate(test_file_name), total=len(test_file_name)):\n    image = Image.open(os.path.join(\"/kaggle/input/prepare-data\", name.strip('./')))\n    inputs = processor(images=image, return_tensors=\"pt\")\n    inputs = inputs.to(device)\n    outputs = model(**inputs)\n    logits = outputs.logits\n    _, preds = torch.max(logits, dim=1)\n    predict_labels.append(model.config.id2label[preds.cpu().item()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.read_csv(\"/kaggle/input/prepare-data/sample_submission.csv\")\nsubmission_df.head()\nsubmission_df['label'] = predict_labels\nsubmission_df.to_csv(\"./submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}