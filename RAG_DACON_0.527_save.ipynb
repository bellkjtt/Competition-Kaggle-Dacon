{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9093008,"sourceType":"datasetVersion","datasetId":5463022}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Question - Answering with Retrieval\n\n본 대회의 과제는 중앙정부 재정 정보에 대한 **검색 기능**을 개선하고 활용도를 높이는 질의응답 알고리즘을 개발하는 것입니다. <br>이를 통해 방대한 재정 데이터를 일반 국민과 전문가 모두가 쉽게 접근하고 활용할 수 있도록 하는 것이 목표입니다. <br><br>\n베이스라인에서는 평가 데이터셋만을 활용하여 source pdf 마다 Vector DB를 구축한 뒤 langchain 라이브러리와 llama-2-ko-7b 모델을 사용하여 RAG 프로세스를 통해 추론하는 과정을 담고 있습니다. <br>( train_set을 활용한 훈련 과정은 포함하지 않으며, test_set  에 대한 추론만 진행합니다. )","metadata":{}},{"cell_type":"markdown","source":"# Download Library","metadata":{}},{"cell_type":"code","source":"!pip install accelerate\n!pip install -i https://pypi.org/simple/ bitsandbytes\n!pip install transformers[torch] -U\n\n!pip install datasets\n!pip install langchain\n!pip install langchain_community\n!pip install PyMuPDF\n!pip install sentence-transformers\n!pip install faiss-gpu","metadata":{"execution":{"iopub.status.busy":"2024-08-04T03:29:17.222315Z","iopub.execute_input":"2024-08-04T03:29:17.222718Z","iopub.status.idle":"2024-08-04T03:31:47.779275Z","shell.execute_reply.started":"2024-08-04T03:29:17.222683Z","shell.execute_reply":"2024-08-04T03:31:47.777976Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.32.1)\nRequirement already satisfied: numpy<2.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2+cpu)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.4)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.5.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nLooking in indexes: https://pypi.org/simple/\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.3\nRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.42.3)\nCollecting transformers[torch]\n  Downloading transformers-4.43.3-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.23.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.32.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2+cpu)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2024.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\nDownloading transformers-4.43.3-py3-none-any.whl (9.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.42.3\n    Uninstalling transformers-4.42.3:\n      Successfully uninstalled transformers-4.42.3\nSuccessfully installed transformers-4.43.3\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nCollecting langchain\n  Downloading langchain-0.2.12-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nCollecting langchain-core<0.3.0,>=0.2.27 (from langchain)\n  Downloading langchain_core-0.2.28-py3-none-any.whl.metadata (6.2 kB)\nCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.96-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\nCollecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.27->langchain)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.9.0)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (2.4)\nDownloading langchain-0.2.12-py3-none-any.whl (990 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.2.28-py3-none-any.whl (379 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.9/379.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\nDownloading langsmith-0.1.96-py3-none-any.whl (140 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, orjson, langsmith, langchain-core, langchain-text-splitters, langchain\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-0.2.12 langchain-core-0.2.28 langchain-text-splitters-0.2.2 langsmith-0.1.96 orjson-3.10.6 packaging-24.1\nCollecting langchain_community\n  Downloading langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (3.9.1)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.7)\nRequirement already satisfied: langchain<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.2.12)\nRequirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.2.28)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.1.96)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (1.26.4)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.12->langchain_community) (0.2.2)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.12->langchain_community) (2.5.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (24.1)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (4.9.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain_community) (2.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain_community) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain_community) (2.14.6)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\nDownloading langchain_community-0.2.11-py3-none-any.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: langchain_community\nSuccessfully installed langchain_community-0.2.11\nCollecting PyMuPDF\n  Downloading PyMuPDF-1.24.9-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\nCollecting PyMuPDFb==1.24.9 (from PyMuPDF)\n  Downloading PyMuPDFb-1.24.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\nDownloading PyMuPDF-1.24.9-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading PyMuPDFb-1.24.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\nSuccessfully installed PyMuPDF-1.24.9 PyMuPDFb-1.24.9\nCollecting sentence-transformers\n  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.43.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.23.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.0.1\nCollecting faiss-gpu\n  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-gpu\nSuccessfully installed faiss-gpu-1.7.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import Library","metadata":{}},{"cell_type":"code","source":"import os\nimport unicodedata\n\nimport torch\nimport pandas as pd\nfrom tqdm import tqdm\nimport fitz  # PyMuPDF\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    pipeline,\n    BitsAndBytesConfig\n)\nfrom accelerate import Accelerator\n\n# Langchain 관련\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import FAISS\nfrom langchain.schema import Document\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.prompts import PromptTemplate\nfrom langchain.schema.runnable import RunnablePassthrough\nfrom langchain.schema.output_parser import StrOutputParser","metadata":{"execution":{"iopub.status.busy":"2024-08-04T03:31:47.781654Z","iopub.execute_input":"2024-08-04T03:31:47.782057Z","iopub.status.idle":"2024-08-04T03:32:09.772442Z","shell.execute_reply.started":"2024-08-04T03:31:47.782014Z","shell.execute_reply":"2024-08-04T03:32:09.771329Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-08-04 03:31:55.865116: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-04 03:31:55.865288: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-04 03:31:56.039654: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install kiwipiepy rank_bm25 openai tiktoken","metadata":{"execution":{"iopub.status.busy":"2024-08-04T03:32:09.773931Z","iopub.execute_input":"2024-08-04T03:32:09.774712Z","iopub.status.idle":"2024-08-04T03:32:34.743094Z","shell.execute_reply.started":"2024-08-04T03:32:09.774678Z","shell.execute_reply":"2024-08-04T03:32:34.741746Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting kiwipiepy\n  Downloading kiwipiepy-0.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\nCollecting rank_bm25\n  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting openai\n  Downloading openai-1.38.0-py3-none-any.whl.metadata (22 kB)\nCollecting tiktoken\n  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nCollecting kiwipiepy-model<0.19,>=0.18 (from kiwipiepy)\n  Downloading kiwipiepy_model-0.18.0.tar.gz (34.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy<2 in /opt/conda/lib/python3.10/site-packages (from kiwipiepy) (1.26.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kiwipiepy) (4.66.4)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.5.3)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.9.0)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.32.3)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\nDownloading kiwipiepy-0.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\nDownloading openai-1.38.0-py3-none-any.whl (335 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.9/335.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: kiwipiepy-model\n  Building wheel for kiwipiepy-model (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for kiwipiepy-model: filename=kiwipiepy_model-0.18.0-py3-none-any.whl size=34843380 sha256=381b078adb5888ad7cf9f32cbf7a2608e0a7cc28ae080fef04ef9fbddeed938e\n  Stored in directory: /root/.cache/pip/wheels/0d/ea/f6/abb93f89cc196467624828ec9c29150c29a8399a589ba50bef\nSuccessfully built kiwipiepy-model\nInstalling collected packages: kiwipiepy-model, rank_bm25, kiwipiepy, tiktoken, openai\nSuccessfully installed kiwipiepy-0.18.0 kiwipiepy-model-0.18.0 openai-1.38.0 rank_bm25-0.2.2 tiktoken-0.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install konlpy","metadata":{"execution":{"iopub.status.busy":"2024-08-04T03:32:34.746820Z","iopub.execute_input":"2024-08-04T03:32:34.747335Z","iopub.status.idle":"2024-08-04T03:32:48.653615Z","shell.execute_reply.started":"2024-08-04T03:32:34.747290Z","shell.execute_reply":"2024-08-04T03:32:48.652158Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting konlpy\n  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\nCollecting JPype1>=0.7.0 (from konlpy)\n  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.10/site-packages (from konlpy) (5.2.2)\nRequirement already satisfied: numpy>=1.6 in /opt/conda/lib/python3.10/site-packages (from konlpy) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from JPype1>=0.7.0->konlpy) (24.1)\nDownloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: JPype1, konlpy\nSuccessfully installed JPype1-1.5.0 konlpy-0.6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pdfplumber","metadata":{"execution":{"iopub.status.busy":"2024-08-04T03:32:48.655291Z","iopub.execute_input":"2024-08-04T03:32:48.655752Z","iopub.status.idle":"2024-08-04T03:33:02.523765Z","shell.execute_reply.started":"2024-08-04T03:32:48.655705Z","shell.execute_reply":"2024-08-04T03:33:02.522285Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting pdfplumber\n  Downloading pdfplumber-0.11.2-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: Pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (9.5.0)\nCollecting pypdfium2>=4.18.0 (from pdfplumber)\n  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\nRequirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (41.0.7)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.21)\nDownloading pdfplumber-0.11.2-py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\nSuccessfully installed pdfminer.six-20231228 pdfplumber-0.11.2 pypdfium2-4.30.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Vector DB","metadata":{}},{"cell_type":"code","source":"from langchain.retrievers import EnsembleRetriever\nfrom langchain_community.retrievers import BM25Retriever\nfrom langchain_core.documents import Document\nfrom langchain.vectorstores import FAISS\nfrom konlpy.tag import Kkma, Okt\nfrom kiwipiepy import Kiwi\n\nkiwi = Kiwi()\nkkma = Kkma()\nokt = Okt()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T03:33:02.525739Z","iopub.execute_input":"2024-08-04T03:33:02.526229Z","iopub.status.idle":"2024-08-04T03:33:06.410808Z","shell.execute_reply.started":"2024-08-04T03:33:02.526182Z","shell.execute_reply":"2024-08-04T03:33:06.409784Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def kiwi_tokenize(text):\n    return [token.form for token in kiwi.tokenize(text)]\n\ndef kkma_tokenize(text):\n    return [token for token in kkma.morphs(text)]\n\ndef okt_tokenize(text):\n    return [token for token in okt.morphs(text)]","metadata":{"execution":{"iopub.status.busy":"2024-08-04T03:33:06.412076Z","iopub.execute_input":"2024-08-04T03:33:06.412403Z","iopub.status.idle":"2024-08-04T03:33:06.418969Z","shell.execute_reply.started":"2024-08-04T03:33:06.412375Z","shell.execute_reply":"2024-08-04T03:33:06.417742Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# def process_pdf(file_path, chunk_size=1500, chunk_overlap=200):\n#     \"\"\"PDF 텍스트 추출 후 chunk 단위로 나누기\"\"\"\n#     # PDF 파일 열기\n#     doc = fitz.open(file_path)\n#     text = ''\n#     # 모든 페이지의 텍스트 추출\n#     for page in doc:\n#         text += page.get_text()\n#     # 텍스트를 chunk로 분할\n#     splitter = RecursiveCharacterTextSplitter(\n#         chunk_size=chunk_size,\n#         chunk_overlap=chunk_overlap\n#     )\n#     chunk_temp = splitter.split_text(text)\n#     # Document 객체 리스트 생성\n#     chunks = [Document(page_content=t) for t in chunk_temp]\n#     return chunks\n\nimport pdfplumber\nfrom langchain.schema import Document\n\nimport os\nimport pdfplumber\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.schema import Document\n\ndef process_pdf(file_path, chunk_size=200, chunk_overlap=20):\n        \"\"\"PDF를 페이지마다 청크로 나누고 메타데이터에 파일 이름 추가\"\"\"\n        # 파일 이름 추출\n        file_name = os.path.basename(file_path)\n        \n        # PDF 파일 열기\n        pdf = pdfplumber.open(file_path)\n        all_chunks = []\n        \n        # 페이지별로 처리\n        for page_number, page in enumerate(pdf.pages):\n            text = page.extract_text()\n            if text:\n                # 페이지별 텍스트 청크로 분할\n                splitter = RecursiveCharacterTextSplitter(\n                    chunk_size=chunk_size,\n                    chunk_overlap=chunk_overlap\n                )\n                chunk_temp = splitter.split_text(text)\n                \n                # Document 객체 리스트 생성 (파일 이름과 페이지 번호를 메타데이터에 포함)\n                page_chunks = [Document(page_content=t, metadata={\"Source\": file_name[:-4], \"page\": page_number}) for t in chunk_temp]\n                all_chunks.extend(page_chunks)\n        \n        pdf.close()  # PDF 파일 닫기\n        return all_chunks\n\n\ndef create_vector_db(chunks, model_path=\"jhgan/ko-sroberta-multitask\"):\n    \"\"\"FAISS DB 생성\"\"\"\n    # 임베딩 모델 설정\n    model_kwargs = {'device': 'cpu'}\n    encode_kwargs = {'normalize_embeddings': True}\n    embeddings = HuggingFaceEmbeddings(\n        model_name=model_path,\n        model_kwargs=model_kwargs,\n        encode_kwargs=encode_kwargs\n    )\n    # FAISS DB 생성 및 반환\n    db = FAISS.from_documents(chunks, embedding=embeddings)\n    return db\n\ndef normalize_path(path):\n    \"\"\"경로 유니코드 정규화\"\"\"\n    return unicodedata.normalize('NFC', path)\n\n\ndef process_pdfs_from_dataframe(df, base_directory):\n    \"\"\"딕셔너리에 pdf명을 키로해서 DB, retriever 저장\"\"\"\n    pdf_databases = {}\n    unique_paths = df['Source_path'].unique()\n    \n    for path in tqdm(unique_paths, desc=\"Processing PDFs\"):\n        # 경로 정규화 및 절대 경로 생성\n        normalized_path = normalize_path(path)\n        full_path = os.path.normpath(os.path.join(base_directory, normalized_path.lstrip('./'))) if not os.path.isabs(normalized_path) else normalized_path\n        \n        pdf_title = os.path.splitext(os.path.basename(full_path))[0]\n        print(f\"Processing {pdf_title}...\")\n        \n        # PDF 처리 및 벡터 DB 생성\n        chunks = process_pdf(full_path)\n#         bm25 = BM25Retriever.from_documents(chunks)\n#         kiwi_bm25 = BM25Retriever.from_documents(chunks, preprocess_func=kiwi_tokenize,  search_kwargs={'k': 20})\n        kkma_bm25 = BM25Retriever.from_documents(chunks, preprocess_func=kkma_tokenize,  search_kwargs={'k': 20})\n        okt_bm25 = BM25Retriever.from_documents(chunks, preprocess_func=okt_tokenize,  search_kwargs={'k': 20})\n        db = create_vector_db(chunks)\n        faiss = db.as_retriever(search_kwargs={'k': 20})\n        \n        # Retriever 생성\n        retriever = EnsembleRetriever(\n                    retrievers=[okt_bm25, faiss],  # 사용할 검색 모델의 리스트\n                    weights=[0.3, 0.7],  # 각 검색 모델의 결과에 적용할 가중치\n                    search_type=\"mmr\",  # 검색 결과의 다양성을 증진시키는 MMR 방식을 사용\n                    search_kwargs={'k': 20, 'fetch_k': 20}, \n                )\n        \n        \n        # 결과 저장\n        pdf_databases[pdf_title] = {\n                'db': db,\n                'retriever': retriever\n        }\n    return pdf_databases","metadata":{"execution":{"iopub.status.busy":"2024-08-04T03:35:50.831792Z","iopub.execute_input":"2024-08-04T03:35:50.832715Z","iopub.status.idle":"2024-08-04T03:35:50.852484Z","shell.execute_reply.started":"2024-08-04T03:35:50.832672Z","shell.execute_reply":"2024-08-04T03:35:50.850804Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# DB 생성","metadata":{}},{"cell_type":"code","source":"# # Train과 Test CSV 파일 모두 로드\n# df_train = pd.read_csv('/kaggle/input/pdf-files/train.csv')\n# df_test = pd.read_csv('/kaggle/input/pdf-files/test.csv')\n\n# # 두 데이터프레임 합치기\n# df_combined = pd.concat([df_train, df_test], ignore_index=True)\n\n# # 중복된 Source_path 제거 (같은 PDF가 train과 test에 모두 있을 경우)\n# df_combined = df_combined.drop_duplicates(subset=['Source_path'])\n\n# base_directory = '/kaggle/input/pdf-files' # Your Base Directory\n# pdf_databases = process_pdfs_from_dataframe(df_combined, base_directory)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T03:33:06.528454Z","iopub.execute_input":"2024-08-04T03:33:06.528807Z","iopub.status.idle":"2024-08-04T03:33:06.535481Z","shell.execute_reply.started":"2024-08-04T03:33:06.528776Z","shell.execute_reply":"2024-08-04T03:33:06.534063Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"%pip install --upgrade --quiet  sentence-transformers > /dev/null","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# base_directory = '/kaggle/input/pdf-files' # Your Base Directory\n# df = pd.read_csv('/kaggle/input/pdf-files/test.csv')\n# pdf_databases = process_pdfs_from_dataframe(df, base_directory)\n# # pdf_databases = process_pdfs_from_dataframe(df, base_directory)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pandas as pd\n\n# # df_train = pd.read_csv('/kaggle/input/pdf-files/train.csv')\n# df_test = pd.read_csv('/kaggle/input/pdf-files/test.csv')\n\n# def group_pdfs(df):\n#     \"\"\"비슷한 PDF 파일을 그룹화\"\"\"\n#     groups = {}\n#     for _, row in df.iterrows():\n#         source_path = row['Source_path']\n#         group_key = source_path.split('_')[0]  # 파일 이름의 특정 부분을 그룹 키로 사용 (예: 'group1_file1.pdf' -> 'group1')\n#         if group_key not in groups:\n#             groups[group_key] = []\n#         groups[group_key].append(source_path)\n#     return groups\n\n# df_combined = pd.concat([df_train, df_test], ignore_index=True)\n# df_combined = df_combined.drop_duplicates(subset=['Source_path'])\n# pdf_groups = group_pdfs(df_combined)\n# pdf_groups","metadata":{"execution":{"iopub.status.busy":"2024-08-04T03:37:47.871095Z","iopub.execute_input":"2024-08-04T03:37:47.871581Z","iopub.status.idle":"2024-08-04T03:37:47.942253Z","shell.execute_reply.started":"2024-08-04T03:37:47.871522Z","shell.execute_reply":"2024-08-04T03:37:47.941073Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'./train': ['./train_source/1-1 2024 주요 재정통계 1권.pdf',\n  './train_source/2024 나라살림 예산개요.pdf',\n  './train_source/재정통계해설.pdf',\n  './train_source/국토교통부_전세임대(융자).pdf',\n  './train_source/고용노동부_청년일자리창출지원.pdf',\n  './train_source/고용노동부_내일배움카드(일반).pdf',\n  './train_source/보건복지부_노인일자리 및 사회활동지원.pdf',\n  './train_source/중소벤처기업부_창업사업화지원.pdf',\n  './train_source/보건복지부_생계급여.pdf',\n  './train_source/국토교통부_소규모주택정비사업.pdf',\n  './train_source/국토교통부_민간임대(융자).pdf',\n  './train_source/고용노동부_조기재취업수당.pdf',\n  './train_source/2024년도 성과계획서(총괄편).pdf',\n  './train_source/조세지출_연계관리.pdf',\n  './train_source/재정융자사업.pdf',\n  './train_source/월간 나라재정 2023년 12월호.pdf'],\n './test': ['./test_source/중소벤처기업부_혁신창업사업화자금(융자).pdf',\n  './test_source/보건복지부_부모급여(영아수당) 지원.pdf',\n  './test_source/보건복지부_노인장기요양보험 사업운영.pdf',\n  './test_source/산업통상자원부_에너지바우처.pdf',\n  './test_source/국토교통부_행복주택출자.pdf',\n  './test_source/재정조정제도.pdf',\n  './test_source/핵심재정사업성과관리.pdf',\n  './test_source/재정성과관리제도.pdf',\n  './test_source/우발부채.pdf']}"},"metadata":{}}]},{"cell_type":"code","source":"import pickle\nimport os\n\ndef save_databases(pdf_databases, save_dir):\n    \"\"\"벡터 데이터베이스와 retriever 저장\"\"\"\n    os.makedirs(save_dir, exist_ok=True)\n    for pdf_title, data in pdf_databases.items():\n        db_path = os.path.join(save_dir, f\"{pdf_title}_db.pkl\")\n        retriever_path = os.path.join(save_dir, f\"{pdf_title}_retriever.pkl\")\n        \n        # DB 저장\n        data['db'].save_local(db_path)\n        \n        # Retriever 저장\n        with open(retriever_path, 'wb') as f:\n            pickle.dump(data['retriever'], f)\n        \n    print(f\"Databases and retrievers saved in {save_dir}\")\n    \nfrom langchain.vectorstores import FAISS\nfrom langchain.embeddings import HuggingFaceEmbeddings\n\ndef load_databases(load_dir, model_path=\"jhgan/ko-sroberta-multitask\"):\n    \"\"\"저장된 벡터 데이터베이스와 retriever 로드\"\"\"\n    pdf_databases = {}\n    \n    # 임베딩 모델 설정\n    model_kwargs = {'device': 'cpu'}\n    encode_kwargs = {'normalize_embeddings': True}\n    embeddings = HuggingFaceEmbeddings(\n        model_name=model_path,\n        model_kwargs=model_kwargs,\n        encode_kwargs=encode_kwargs\n    )\n    \n    for filename in os.listdir(load_dir):\n        if filename.endswith(\"_db.pkl\"):\n            pdf_title = filename[:-7]  # Remove \"_db.pkl\"\n            db_path = os.path.join(load_dir, filename)\n            retriever_path = os.path.join(load_dir, f\"{pdf_title}_retriever.pkl\")\n            \n            # DB 로드 (allow_dangerous_deserialization 파라미터 추가)\n            db = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)\n            \n            # Retriever 로드\n            with open(retriever_path, 'rb') as f:\n                retriever = pickle.load(f)\n            \n            pdf_databases[pdf_title] = {\n                'db': db,\n                'retriever': retriever\n            }\n    \n    print(f\"Loaded {len(pdf_databases)} databases from {load_dir}\")\n    return pdf_databases\n\n\n# # # 데이터베이스 생성 후 저장\n# Train과 Test CSV 파일 모두 로드\n\ndf_test = pd.read_csv('/kaggle/input/pdf-files/test.csv')\n\nbase_directory = '/kaggle/input/pdf-files' # Your Base Directory\npdf_databases = process_pdfs_from_dataframe(df_test, base_directory)\n\nsave_dir = '/kaggle/working/'\nsave_databases(pdf_databases, save_dir)\n\n# 나중에 데이터베이스 로드\npdf_databases = load_databases(save_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T03:48:14.297994Z","iopub.execute_input":"2024-08-04T03:48:14.298395Z","iopub.status.idle":"2024-08-04T03:57:15.404871Z","shell.execute_reply.started":"2024-08-04T03:48:14.298366Z","shell.execute_reply":"2024-08-04T03:57:15.403151Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Processing PDFs:   0%|          | 0/9 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Processing 중소벤처기업부_혁신창업사업화자금(융자)...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n  warn_deprecated(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08409c018a194674a7913331ecd38124"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"288042874f3f497bb67e5f30f46fe13f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/4.86k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4e3e13f24774a6d822266f5a0707be1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"082e32e009ec481fa3a90cf787a39750"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/744 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79cd52e13ec040d58d46440d1710043d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5af59b0bee4647278958080a9b23bb1c"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/585 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"132c1c1e130147c0845eb6f904c3eed5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83427ce790744658a318324e531906e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07204729e5d848dcb377377b67e68a02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd211373a5784cdfb791d526cdf6504d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0703726d5f4c43888f6c0655c1f99e19"}},"metadata":{}},{"name":"stderr","text":"Processing PDFs:  11%|█         | 1/9 [01:01<08:14, 61.80s/it]","output_type":"stream"},{"name":"stdout","text":"Processing 보건복지부_부모급여(영아수당) 지원...\n","output_type":"stream"},{"name":"stderr","text":"Processing PDFs:  22%|██▏       | 2/9 [01:12<03:41, 31.69s/it]","output_type":"stream"},{"name":"stdout","text":"Processing 보건복지부_노인장기요양보험 사업운영...\n","output_type":"stream"},{"name":"stderr","text":"Processing PDFs:  33%|███▎      | 3/9 [01:33<02:41, 26.99s/it]","output_type":"stream"},{"name":"stdout","text":"Processing 산업통상자원부_에너지바우처...\n","output_type":"stream"},{"name":"stderr","text":"Processing PDFs:  44%|████▍     | 4/9 [02:03<02:21, 28.20s/it]","output_type":"stream"},{"name":"stdout","text":"Processing 국토교통부_행복주택출자...\n","output_type":"stream"},{"name":"stderr","text":"Processing PDFs:  56%|█████▌    | 5/9 [02:20<01:36, 24.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processing 재정조정제도...\n","output_type":"stream"},{"name":"stderr","text":"Processing PDFs:  67%|██████▋   | 6/9 [03:19<01:48, 36.02s/it]","output_type":"stream"},{"name":"stdout","text":"Processing 핵심재정사업성과관리...\n","output_type":"stream"},{"name":"stderr","text":"Processing PDFs:  78%|███████▊  | 7/9 [04:22<01:29, 44.66s/it]","output_type":"stream"},{"name":"stdout","text":"Processing 재정성과관리제도...\n","output_type":"stream"},{"name":"stderr","text":"Processing PDFs:  89%|████████▉ | 8/9 [05:05<00:44, 44.26s/it]","output_type":"stream"},{"name":"stdout","text":"Processing 우발부채...\n","output_type":"stream"},{"name":"stderr","text":"Processing PDFs: 100%|██████████| 9/9 [06:00<00:00, 40.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Databases and retrievers saved in /kaggle/working/\nLoaded 9 databases from /kaggle/working/\n","output_type":"stream"}]},{"cell_type":"code","source":"# # save_dir = '/kaggle/working/'\n# # # save_databases(pdf_databases, save_dir)\n# import pickle\n\n# def load_databases(load_dir, model_path=\"paraphrase-multilingual-mpnet-base-v2\"):\n#     \"\"\"저장된 벡터 데이터베이스와 retriever 로드\"\"\"\n#     pdf_databases = {}\n    \n#     # 임베딩 모델 설정\n#     model_kwargs = {'device': 'cpu'}\n#     encode_kwargs = {'normalize_embeddings': True}\n#     embeddings = HuggingFaceEmbeddings(\n#         model_name=model_path,\n#         model_kwargs=model_kwargs,\n#         encode_kwargs=encode_kwargs\n#     )\n    \n#     for filename in os.listdir(load_dir):\n#         if filename.endswith(\"_db.pkl\"):\n#             pdf_title = filename[:-7]  # Remove \"_db.pkl\"\n#             db_path = os.path.join(load_dir, filename)\n#             retriever_path = os.path.join(load_dir, f\"{pdf_title}_retriever.pkl\")\n            \n#             # DB 로드 (allow_dangerous_deserialization 파라미터 추가)\n#             db = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)\n            \n#             # Retriever 로드\n#             with open(retriever_path, 'rb') as f:\n#                 retriever = pickle.load(f)\n            \n#             pdf_databases[pdf_title] = {\n#                 'db': db,\n#                 'retriever': retriever\n#             }\n    \n#     print(f\"Loaded {len(pdf_databases)} databases from {load_dir}\")\n#     return pdf_databases\n\n# save_dir = '/kaggle/working/'\n# # # 나중에 데이터베이스 로드\n# pdf_databases = load_databases(save_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL Import","metadata":{}},{"cell_type":"code","source":"# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n# from huggingface_hub import login\n\n# # 인증 토큰 설정\n# login(token='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')\n\n# def setup_llm_pipeline():\n#     # 모델 ID \n#     model_id = \"MLP-KTLim/llama-3-Korean-Bllossom-8B\"\n\n#     # 토크나이저 로드 및 설정\n#     tokenizer = AutoTokenizer.from_pretrained(model_id)\n#     tokenizer.use_default_system_prompt = False\n\n#     # 모델 로드\n#     model = AutoModelForCausalLM.from_pretrained(\n#         model_id,\n#         torch_dtype=torch.float16,  # 16비트 부동소수점 사용\n#         device_map=\"auto\",\n#         trust_remote_code=True )\n\n#     # HuggingFacePipeline 객체 생성\n#     text_generation_pipeline = pipeline(\n#         model=model,\n#         tokenizer=tokenizer,\n#         task=\"text-generation\",\n#         temperature=0.4,\n#         do_sample= True,\n#         return_full_text=False,\n#         max_new_tokens=512,\n#         repetition_penalty=1.2,  # 반복 억제\n#         no_repeat_ngram_size=3,  # n-gram 반복 방지\n#         num_beams=4,  # beam search 사용\n#         early_stopping=True,  \n#     )\n\n#     hf = HuggingFacePipeline(pipeline=text_generation_pipeline)\n\n#     return hf\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GPU 메모리 비우기\nimport gc\ndel llm\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def setup_llm_pipeline():\n    # 4비트 양자화 설정\n    bnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_use_double_quant=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=torch.bfloat16\n    )\n\n    # 모델 ID \n    model_id = \"MLP-KTLim/llama-3-Korean-Bllossom-8B\"\n#     token='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'\n    # 토크나이저 로드 및 설정\n    tokenizer = AutoTokenizer.from_pretrained(model_id)\n    tokenizer.use_default_system_prompt = False\n\n    # 모델 로드 및 양자화 설정 적용\n    model = AutoModelForCausalLM.from_pretrained(\n        model_id,\n        quantization_config=bnb_config,\n        device_map=\"auto\",\n        trust_remote_code=True )\n\n    # HuggingFacePipeline 객체 생성\n    text_generation_pipeline = pipeline(\n        model=model,\n        tokenizer=tokenizer,\n        task=\"text-generation\",\n        temperature=0.2,\n        do_sample= True,\n        return_full_text=False,\n        max_new_tokens=512,\n        repetition_penalty=1.2,  # 반복 억제\n        no_repeat_ngram_size=3,  # n-gram 반복 방지\n#         num_beams=4,  # beam search 사용\n#         early_stopping=True,  \n    )\n\n\n    hf = HuggingFacePipeline(pipeline=text_generation_pipeline)\n\n    return hf","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:49:14.194967Z","iopub.execute_input":"2024-08-03T13:49:14.196079Z","iopub.status.idle":"2024-08-03T13:49:14.203153Z","shell.execute_reply.started":"2024-08-03T13:49:14.196038Z","shell.execute_reply":"2024-08-03T13:49:14.202210Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# LLM 파이프라인\nllm = setup_llm_pipeline()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:49:14.204419Z","iopub.execute_input":"2024-08-03T13:49:14.204768Z","iopub.status.idle":"2024-08-03T13:50:41.449824Z","shell.execute_reply.started":"2024-08-03T13:49:14.204735Z","shell.execute_reply":"2024-08-03T13:50:41.448866Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff698a5d4bcd46f2bb847718790189a6"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFacePipeline`.\n  warn_deprecated(\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install groq","metadata":{"execution":{"iopub.status.busy":"2024-08-04T03:57:29.115375Z","iopub.execute_input":"2024-08-04T03:57:29.116511Z","iopub.status.idle":"2024-08-04T03:57:41.785249Z","shell.execute_reply.started":"2024-08-04T03:57:29.116467Z","shell.execute_reply":"2024-08-04T03:57:41.783741Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: groq in /opt/conda/lib/python3.10/site-packages (0.9.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from groq) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from groq) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from groq) (0.27.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from groq) (2.5.3)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from groq) (1.3.0)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from groq) (4.9.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (3.6)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (2024.7.4)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (2.14.6)\n","output_type":"stream"}]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"GROQ_API_KEY\")\nsecret_value_0","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:01:16.569601Z","iopub.execute_input":"2024-08-04T04:01:16.570070Z","iopub.status.idle":"2024-08-04T04:01:16.886264Z","shell.execute_reply.started":"2024-08-04T04:01:16.570034Z","shell.execute_reply":"2024-08-04T04:01:16.884805Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"'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'"},"metadata":{}}]},{"cell_type":"code","source":"import os\nfrom groq import Groq\n\nclient = Groq(\n    api_key=secret_value_0,\n)\n\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"always answer with korean only \",\n            \"role\": \"user\",\n            \"content\": \"아이브 안유진의 키는 몇 cm? \",\n        }\n    ],\n    model=\"llama3-70b-8192\",\n    temperature=1,\n    max_tokens=1024,\n    top_p=1,\n    stream=True,\n    stop=None,\n)\n\n\nfor chunk in chat_completion:\n    print(chunk.choices[0].delta.content or \"\", end=\"\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:01:17.860887Z","iopub.execute_input":"2024-08-04T04:01:17.861337Z","iopub.status.idle":"2024-08-04T04:01:18.289507Z","shell.execute_reply.started":"2024-08-04T04:01:17.861304Z","shell.execute_reply":"2024-08-04T04:01:18.288204Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"😊\n\nAccording to various sources, including her profile on the IVE official website and other online platforms, An Yujin's height is 163 cm (5 feet 4 inches).","output_type":"stream"}]},{"cell_type":"markdown","source":"# Langchain 을 이용한 추론","metadata":{}},{"cell_type":"code","source":"\n    # 소스 문자열 정규화\nsource = normalize_string(df['Source'][0])\nquestion = df['Question'][0]\nprint(question,'요게 질문')\n# 정규화된 키로 데이터베이스 검색\nnormalized_keys = {normalize_string(k): v for k, v in pdf_databases.items()}\nretriever = normalized_keys[source]['retriever']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"source","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normalized_keys[source]['retriever']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retriever | format_docs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from langchain_core.prompts import format_document\nretrieved_docs = retriever.invoke(question)\nprint(retrieved_docs)\n\nprint(\"--------\")\n\n\nreordering = LongContextReorder()\nreordered_docs = reordering.transform_documents(retrieved_docs )\nprint(reordered_docs)\n# print(\"\\n\\n\".join(doc.page_content for doc in reordered_docs))\n\nDEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(\n    template=\"{page_content} [source: {soruce}]\"\n)\n\ndef combine_documents(\n    docs,  # 문서 목록\n    # 문서 프롬프트 (기본값: DEFAULT_DOCUMENT_PROMPT)\n    document_prompt=DEFAULT_DOCUMENT_PROMPT,\n    document_separator=\"\\n\",  # 문서 구분자 (기본값: 두 개의 줄바꿈)\n):\n    # context 에 입력으로 넣기 위한 문서 병합\n    doc_strings = [\n        f\"[{i}] {format_document(doc, document_prompt)}\" for i, doc in enumerate(docs)\n    ]  # 각 문서를 주어진 프롬프트로 포맷팅하여 문자열 목록 생성\n    return document_separator.join(\n        doc_strings\n    )  # 포맷팅된 문서 문자열을 구분자로 연결하여 반환\n\ncombined = combine_documents(reordered_docs, document_separator=\"\\n\")\nprint(combined)\n# retriever = normalized_keys[source]['retriever']\n# rag_chain = (\n#         retriever | format_docs )\n# formatted_docs = rag_chain.invoke(question)\n# print(formatted_docs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question = df['Question'][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retriever.invoke(question)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import langchain\nlangchain.debug = True\n\nprint()\n    \nrag_chain = (\n        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n        | prompt)\nrag_chain.invoke(question)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/pdf-files/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:10:25.154774Z","iopub.execute_input":"2024-08-04T04:10:25.155162Z","iopub.status.idle":"2024-08-04T04:10:25.207830Z","shell.execute_reply.started":"2024-08-04T04:10:25.155133Z","shell.execute_reply":"2024-08-04T04:10:25.206287Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"retriever","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" prompt = PromptTemplate.from_template(\n        \"\"\"You are an assistant for question-answering tasks. \n    Use the following pieces of retrieved context to answer the question. \n    If you don't know the answer, just say that you don't know. \n    Answer in Korean.\n\n    #Question: \n    {question} \n    #Context: \n    {context} \n\n    #Answer:\"\"\"\n    )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API key: \")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:14:32.481168Z","iopub.execute_input":"2024-08-04T04:14:32.481672Z","iopub.status.idle":"2024-08-04T04:14:41.249820Z","shell.execute_reply.started":"2024-08-04T04:14:32.481637Z","shell.execute_reply":"2024-08-04T04:14:41.248515Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdin","text":"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 ························································\n"}]},{"cell_type":"code","source":"%pip install -qU langchain-groq","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:15:00.727665Z","iopub.execute_input":"2024-08-04T04:15:00.728110Z","iopub.status.idle":"2024-08-04T04:15:14.192430Z","shell.execute_reply.started":"2024-08-04T04:15:00.728076Z","shell.execute_reply":"2024-08-04T04:15:14.190883Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain_groq import ChatGroq\n\nllm = ChatGroq(\n    model=\"llama-3.1-70b-versatile\",\n    temperature=0.2,\n    max_tokens=1024,\n    timeout=None,\n    stop=None,\n    max_retries=2,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:37:37.569036Z","iopub.execute_input":"2024-08-04T04:37:37.570085Z","iopub.status.idle":"2024-08-04T04:37:37.604961Z","shell.execute_reply.started":"2024-08-04T04:37:37.570044Z","shell.execute_reply":"2024-08-04T04:37:37.603820Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"from langchain_community.document_transformers import LongContextReorder\nfrom langchain.prompts import ChatPromptTemplate\nfrom operator import itemgetter\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnableLambda\nfrom langchain_core.prompts import format_document\nfrom langchain_core.prompts import ChatPromptTemplate\n\ndef normalize_string(s):\n    \"\"\"유니코드 정규화\"\"\"\n    return unicodedata.normalize('NFC', s)\n\n# 기본 문서 프롬프트를 생성합니다. (source, metadata 등을 추가할 수 있습니다)\nDEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(\n    template=\"{page_content} [source: {Source}]\"\n)\n\ndef combine_documents(\n    docs,  # 문서 목록\n    # 문서 프롬프트 (기본값: DEFAULT_DOCUMENT_PROMPT)\n    document_prompt=DEFAULT_DOCUMENT_PROMPT,\n    document_separator=\"\\n\",  # 문서 구분자 (기본값: 두 개의 줄바꿈)\n):\n    # context 에 입력으로 넣기 위한 문서 병합\n    doc_strings = [\n        f\"[{i}] {format_document(doc, document_prompt)}\" for i, doc in enumerate(docs)\n    ]  # 각 문서를 주어진 프롬프트로 포맷팅하여 문자열 목록 생성\n    return document_separator.join(\n        doc_strings\n    )  # 포맷팅된 문서 문자열을 구분자로 연결하여 반환\n\n\ndef reorder_documents(docs):\n    # 재정렬\n    reordering = LongContextReorder()\n    reordered_docs = reordering.transform_documents(docs)\n    combined = combine_documents(reordered_docs, document_separator=\"\\n\")\n    return combined\n\n\n\n\ndef format_docs(docs):\n    \"\"\"검색된 문서들을 하나의 문자열로 포맷팅\"\"\"\n        # docs가 리스트가 아닌 경우 (예: Retriever 객체)\n    reordering = LongContextReorder()\n    reordered_docs = reordering.transform_documents(docs)\n    return \"\\n\\n\".join(doc.page_content for doc in reordered_docs)\n\nimport re\n\ndef remove_html_tags(text):\n    \"\"\"HTML 태그를 제거하는 함수\"\"\"\n    clean = re.compile('<.*?>')\n    return re.sub(clean, '', text)    \n\ndef clean_output(output):\n    # \"질문:\" 이후의 텍스트만 반환하고 HTML 태그 제거\n    if \"Answer:\" in output:\n        output = output.split(\"Answer:\")[-1].strip()\n    return remove_html_tags(output)\n\n# 결과를 저장할 리스트 초기화\nresults = []\nnormalized_keys = {normalize_string(k): v for k, v in pdf_databases.items()}\n# DataFrame의 각 행에 대해 처리\nfor _, row in tqdm(df.iterrows(), total=len(df), desc=\"Answering Questions\"):\n    # 소스 문자열 정규화\n    source = normalize_string(row['Source'])\n    question = row['Question']\n    # 정규화된 키로 데이터베이스 검색\n    normalized_keys = {normalize_string(k): v for k, v in pdf_databases.items()}\n    retriever = normalized_keys[source]['retriever']\n    \n    # RAG 체인 구성\n#     prompt = PromptTemplate.from_template(\n#        template = \"\"\"Given this text extracts:\n#     {context}\n\n#     -----\n#     Please answer the following question:\n#     {question}\n\n#     Answer in the following languages: {language}\n#     \"\"\"\n#     )\n    \n\n\n    prompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            \"You are a helpful assistant that answers question with {context}.\",\n        ),\n        (\"human\", \"Please answer the following question: {question}. Think step by step. Answer in the following languages: {language}\"),\n    ]\n    )\n\n    # RAG 체인 정의\n    rag_chain = (\n    {\n        \"context\": itemgetter(\"question\")\n        | retriever\n        | RunnableLambda(reorder_documents),  # 질문을 기반으로 문맥을 검색합니다.\n        \"question\": itemgetter(\"question\"),  # 질문을 추출합니다.\n        \"language\": itemgetter(\"language\"),  # 답변 언어를 추출합니다.\n    }\n    | prompt  # 프롬프트 템플릿에 값을 전달합니다.\n    | llm\n    | StrOutputParser()  # 모델의 출력을 문자열로 파싱합니다.\n    )\n\n    # 답변 추론\n    print(f\"Question: {question}\")\n    full_response = rag_chain.invoke({\"question\": question, \"language\": \"KOREAN\"})\n\n    # 실제 답변만 추출\n    actual_answer = clean_output(full_response)\n    print(f\"Answer: {actual_answer}\\n\")\n\n    # 결과 저장\n    results.append({\n        \"Source\": row['Source'],\n        \"Source_path\": row['Source_path'],\n        \"Question\": question,\n        \"Answer\": actual_answer  # 실제 답변만 저장\n    })\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:37:45.177767Z","iopub.execute_input":"2024-08-04T04:37:45.178206Z","iopub.status.idle":"2024-08-04T04:37:45.767778Z","shell.execute_reply.started":"2024-08-04T04:37:45.178170Z","shell.execute_reply":"2024-08-04T04:37:45.765596Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stderr","text":"Answering Questions:   0%|          | 0/98 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Question: 2022년 혁신창업사업화자금(융자)의 예산은 얼마인가요?\n","output_type":"stream"},{"name":"stderr","text":"Answering Questions:   0%|          | 0/98 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","Cell \u001b[0;32mIn[52], line 116\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# 답변 추론\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m full_response \u001b[38;5;241m=\u001b[39m \u001b[43mrag_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlanguage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mKOREAN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# 실제 답변만 추출\u001b[39;00m\n\u001b[1;32m    119\u001b[0m actual_answer \u001b[38;5;241m=\u001b[39m clean_output(full_response)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/runnables/base.py:2875\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2873\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2874\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2875\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2876\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2877\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:274\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    270\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    271\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    273\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    284\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:714\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    708\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    712\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    713\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:571\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    570\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    572\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    573\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    575\u001b[0m ]\n\u001b[1;32m    576\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:561\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    560\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 561\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m         )\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:793\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 793\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_groq/chat_models.py:472\u001b[0m, in \u001b[0;36mChatGroq._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    468\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    471\u001b[0m }\n\u001b[0;32m--> 472\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/groq/resources/chat/completions.py:289\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    178\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/groq/_base_client.py:1225\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1213\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1222\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1223\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1224\u001b[0m     )\n\u001b[0;32m-> 1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/groq/_base_client.py:920\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    913\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    918\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    919\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 920\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/groq/_base_client.py:1018\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1015\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1017\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1018\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1021\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1022\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1026\u001b[0m )\n","\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'message': 'The model `llama-3.1-405b-reasoning` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}}"],"ename":"NotFoundError","evalue":"Error code: 404 - {'error': {'message': 'The model `llama-3.1-405b-reasoning` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}}","output_type":"error"}]},{"cell_type":"code","source":"pdf_databases.items()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from langchain.schema import Document\nfrom langchain_community.document_transformers import LongContextReorder\nimport unicodedata\nimport re\n\ndef normalize_string(s):\n    \"\"\"유니코드 정규화\"\"\"\n    return unicodedata.normalize('NFC', s)\n\ndef format_docs(docs):\n    \"\"\"검색된 문서들을 하나의 문자열로 포맷팅하고 소스를 포함\"\"\"\n    reordering = LongContextReorder()\n    reordered_docs = reordering.transform_documents(docs)\n    return \"\\n\\n\".join(f\"Source: {source}\\n{doc.page_content}\" for doc in reordered_docs)\n\ndef remove_html_tags(text):\n    \"\"\"HTML 태그를 제거하는 함수\"\"\"\n    clean = re.compile('<.*?>')\n    return re.sub(clean, '', text)\n\ndef clean_output(output):\n    \"\"\"\"질문:\" 이후의 텍스트만 반환하고 HTML 태그 제거\"\"\"\n    if \"답변만 작성하세요:\" in output:\n        output = output.split(\"답변만 작성하세요:\")[-1].strip()\n    return remove_html_tags(output)\n\n# 결과를 저장할 리스트 초기화\nresults = []\nnormalized_keys = {normalize_string(k): v for k, v in pdf_databases.items()}\n\n# DataFrame의 각 행에 대해 처리\nfor _, row in tqdm(df.iterrows(), total=len(df), desc=\"Answering Questions\"):\n    # 소스 문자열 정규화\n    source = normalize_string(row['Source'])\n    question = row['Question']\n    print(question, '요게 질문')\n\n    # 정규화된 키로 데이터베이스 검색\n    retriever = normalized_keys[source]['retriever']\n    \n    # RAG 체인 구성\n    prompt = PromptTemplate.from_template(\n    \"\"\"당신은 사용자들의 질문과 문맥을 받아 답변을 도와주는 지능형 어시스턴트입니다. \n    반드시 다음의 문맥 조각들만 사용하여 질문에 답변하세요. 단계별로 생각한 후 답변하세요.\n\n    답변을 가짜로 만들어내지 마세요:\n     - 만약 문맥에서 질문의 답을 결정할 수 없다면 \"그 질문에 대한 답을 결정할 수 없습니다.\"라고 하세요.\n     - 문맥이 비어 있으면 \"그 질문에 대한 답을 모릅니다.\"라고 하세요.\n\n    답변은 반드시 한국어로 하세요. 설명은 필요 없습니다.\n    \n    예시 1:\n    질문 : 2024년도 국세수입 중 일반회계 내국세수입은 몇 조원인가요?\n    답변 : 2024년도 일반회계 내국세수입은 321.6조원입니다.\n    \n    예시 2:\n    질문 : 2024년도 세외수입 규모와 구성은 어떤가요?\n    답변 : 2024년 세외수입은 일반회계에서 11.2조원, 특별회계에서 17.0조원으로 나타났습니다.\n\n\n    #문맥: \n    {context}\n\n    #질문:\n    {question}\n\n    #답변만 작성하세요:\"\"\"\n)\n\n\n    # RAG 체인 정의\n    rag_chain = (\n    {\n        \"context\": itemgetter(\"question\")\n        | faiss\n        | RunnableLambda(reorder_documents),  # 질문을 기반으로 문맥을 검색합니다.\n        \"question\": itemgetter(\"question\"),  # 질문을 추출합니다.\n        \"language\": itemgetter(\"language\"),  # 답변 언어를 추출합니다.\n    }\n    | prompt  # 프롬프트 템플릿에 값을 전달합니다.\n#     | ChatOpenAI()  # 언어 모델에 프롬프트를 전달합니다.\n#     | StrOutputParser()  # 모델의 출력을 문자열로 파싱합니다.\n)\n\n    # 답변 추론\n    print(f\"Question: {question}\")\n    full_response = rag_chain.invoke(question)\n\n    # 실제 답변만 추출\n    actual_answer = clean_output(full_response)\n    print(f\"Answer: {actual_answer}\\n\")\n\n    # 결과 저장\n    results.append({\n        \"Source\": row['Source'],\n        \"Source_path\": row['Source_path'],\n        \"Question\": question,\n        \"Answer\": actual_answer  # 실제 답변만 저장\n    })\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"# 제출용 샘플 파일 로드\nsubmit_df = pd.read_csv(\"/kaggle/input/pdf-files/sample_submission.csv\")\n\n# 생성된 답변을 제출 DataFrame에 추가\nsubmit_df['Answer'] = [item['Answer'] for item in results]\nsubmit_df['Answer'] = submit_df['Answer'].fillna(\"데이콘\")     # 모델에서 빈 값 (NaN) 생성 시 채점에 오류가 날 수 있음 [ 주의 ]\n\n# 결과를 CSV 파일로 저장\nsubmit_df.to_csv(\"./baseline_submission_ensembel_405.csv\", encoding='UTF-8-sig', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:33:04.323473Z","iopub.execute_input":"2024-08-04T04:33:04.324059Z","iopub.status.idle":"2024-08-04T04:33:04.339835Z","shell.execute_reply.started":"2024-08-04T04:33:04.324013Z","shell.execute_reply":"2024-08-04T04:33:04.338178Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}